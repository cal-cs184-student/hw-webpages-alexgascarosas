<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Names: Alex Gasca Rosas</div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-alexgascarosas/hw1/index.html">Homework 1 Webpage (sp25)</a>
		
		<br>

		Link to GitHub code repository: <a href="https://github.com/cal-cs184-student/hw1-rasterizer-cs-284a-student-team/tree/main">My Github</a>
		Link to GitHub hw repository: <a href="https://github.com/cal-cs184-student/hw-webpages-alexgascarosas">My Github</a>

		<!--
			<figure>
				<img src="lion.jpg" alt="Lion" style="width:50%"/>
				<figcaption>You can add images with captions!</figcaption>
			</figure>
		-->

		<h2>Overview</h2>
		<p>
        For homework 1 I built a software rasterizer pipeline for Scalable Vector Graphics (SVGs). I implemented...
		<ol>
			<li>a single-color triangle rasterization using edge functions,</li>
			<li>a supersampling antialiasing using a per-subsample buffer and resolve step,</li>
			<li>SVG transforms - translate/scale/rotate - in homogeneous coordinates,.</li>
			<li>barycentric coordinates for smooth interpolated vertex colors,</li>
			<li>texture mapping with nearest & bilinear pixel sampling, & </li>
			<li>a mipmapped level sampling - L_ZERO/L_NEAREST/L_LINEAR - including trilinear filtering.</li>
		</ol>
        <p>
        The most interesting takeaway was that everything is built from the same triangle backbone. It is cool and 
		interesting to see that everything in homework 1 was ultimatley made from multiple single triangles.
		</p>


		<h2>Task 1: Drawing Single-Color Triangles</h2> 

		<h3>Algorithm</h3>
      	<p>
			To rasterize a triangle, I first transformed its three vertices into screen space. Once I had the 2D coordinates, 
			I computed the triangle’s axis-aligned bounding box by taking the minimum and maximum x and y values among each vertex. 
			
			I then iterate over every pixel inside this bounding box. For each sample point, I determined whether it lies inside the 
			triangle using edge function. Each triangle edge defines a line, and the interior of the triangle is the intersection of
			the three corresponding half-planes. If the sample lies on the correct side of all three edges,  it is inside the triangle.
			
			For these samples inside the triangle, I finally computed barycentric coordinates to interpolate attributes such as color and depth.
		</p>

		<h3>Why algorithm is no worse than bounding-box sampling</h3>
		<p>
			The algorithm only checks samples inside the triangle’s bounding box. We let N be the number of samples inside the triangle's 
			bounding box. Since the algorithm examines only samples within this bounding box and performs a constant-time inside-triangle test for
			each sample, this would take constant time. Runtime is \(O(N)\). 
 
			This is no worse than an algorithm that checks every sample within the bounding box, since both approaches iterate over the same set 
			of candidate samples and perform constant work per sample.
		</p>


		<h3>Images</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="hw1_1_full.png" width="500px"/>
				  <figcaption>Screenshot #1: basic/test4.svg</figcaption>
				  <figcaption>(default view, sample rate 1)</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
					<div style="display: flex; justify-content: center; gap: 20px;">
					<div>
						<img src="hw1_1_zoom.png" width="300px"/>
						<figcaption>Screenshot #2. Pixel inspector placed on left end of red triangle.</figcaption>
					</div>
					<div>
						<img src="hw1_1_zoom2.png" width="300px"/>
						<figcaption>Screenshot #3. Pixel inspector placed on right end of red triangle and top of purple triangle.</figcaption>
					</div>
					</div>
				</td>
			  </tr>
			</table>
		</div>

		<h3>Extra Credit</h3>

		<style>
			.styled-table {
				margin-left: auto;
				margin-right: auto;
				border-collapse: collapse;
				width: 60%;
				text-align: center;
			}
			.styled-table th, .styled-table td {
				border: 1px solid #ddd;
				padding: 8px;
			}
		</style>

		<table class="styled-table">
			<thead>
				<tr>
					<th></th>
					<th>Basic Optimization times (ms)</th>
					<th>Special Optimization times (ms)</th>
				</tr>
			</thead>
			<tbody>
				<tr>
					<th>1</th>
					<th>0.6349</th>
					<th>0.4391</th>
				</tr>
				<tr>
					<th>2</th>
					<th>0.6156</th>
					<th>0.4089</th>
				</tr>
				<tr>
				<tr>
					<th>3</th>
					<th>0.6014</th>
					<th>0.3433</th>
				</tr>
				<tr>
					<th>4</th>
					<th>0.4234</th>
					<th>0.2560</th>
				</tr>
				<tr>
					<th>5</th>
					<th>0.5971</th>
					<th>0.2546</th>
				</tr>
				<tr>
					<th>6</th>
					<th>0.4296</th>
					<th>0.2599</th>
				</tr>
				<tr>
				<tr>
					<th>7</th>
					<th>0.4229</th>
					<th>0.2652</th>
				</tr>
				<tr>
					<th>8</th>
					<th>0.6048</th>
					<th>0.2776</th>
				</tr>
				<tr>
					<th>9</th>
					<th>0.8776</th>
					<th>0.3915</th>
				</tr>
				<tr>
					<th>10</th>
					<th>0.4252</th>
					<th>0.2626</th>
				</tr>
				<tr>
					<th>Average</th>
					<th>0.56252</th>
					<th>0.31581</th>
				</tr>
			</tbody>
		</table>

		<br>

		<table class="styled-table">
			<thead>
				<tr>
					<th></th>
					<th>Timing Results (ms)</th>
				</tr>
			</thead>
			<tbody>
				<tr>
					<th>Basic Optimization</th>
					<th>0.56325</th>
				</tr>
				<tr>
					<th>Special Optimization</th>
					<th>0.31581</th>
				</tr>
				<tr>
				<tr>
					<th>Speedup</th>
					<th>1.7835</th>
				</tr>
			</tbody>
		</table>

		<br>

		<p>For speed optimization I used incremental edge evaluation. Instead of recomputing
        \(L_i(x,y)\) from scratch for every pixel, I computed the edge values once at the start of each scanline
        and then incrementally updated them as x increases: \(L_i(x+1,y) = L_i(x,y) + A_i\). 
		This optimization removed repeated multiplies from the inner loop and reduced redundant code.
      	</p>

      	<p>
        To get how much faster the optimized code ran vs the basic one, I measured performance by timing <code>svg.draw(...)</code> inside <code>DrawRend::redraw()</code>
        using the built in clock <code>std::chrono::high_resolution_clock</code>. I ran each version 10 times and took the average and found just by using incremental edge evalution my
		overall performance increasd by a speed of 1.8, almost doubling the performance speed.

		
		<h2>Task 2: Antialiasing by Supersampling</h2>

		<h3>Algorithm</h3>
      	<p>
			I implemented supersampling by rasterizing into a supersample buffer instead of writing directly
			into the final framebuffer. I stored:
		</p>
		<ul>
			<li>
				<code>sample_rate = N</code> sub-samples per pixel.
			</li>
			<li>
				<code>sdim = sqrt(sample_rate)</code>, so each pixel has an <code>sdim × sdim</code> grid of sub-samples.
			</li>
			<li>
				A <code>sample_buffer</code> of size <code>width * height * sample_rate</code>, where each entry stores a color
				for a single sub-sample.
			</li>
		</ul>
		<p>
			Conceptually, all sub-samples for pixel <code>(x, y)</code> are stored contiguously:
		</p>
			<pre>
				<code>
					base = (y * width + x) * sample_rate
				    sample_index = base + s   // s in [0, sample_rate)
			    </code>
			</pre>

		<p>
			I still compute the triangle’s axis-aligned bounding box in pixel coordinates. The difference here is that inside
			the bounding box I test every sub-sample location instead of only the pixel center 
		</p>
		<ol>
			<li>
				I computed and clamped the triangle bounding box to the screen.
			</li>
			<li>
				I then looped over each pixel <code>(x, y)</code> in the bounding box.
			</li>
			<li>
				Then looped over each sub-sample <code>(i, j)</code> in an <code>sdim × sdim</code> grid and evaluate the point:
				<pre>
					<code>
						sx = x + (i + 0.5) / sdim
				        sy = y + (j + 0.5) / sdim
					</code>
				</pre>
			</li>
			<li>
				Then I ran the same point-in-triangle test -edge functions / half-plane tests- at <code>(sx, sy)</code>.
				If inside, write the triangle’s color into the corresponding entry of <code>sample_buffer</code>.
			</li>
		</ol>

		<p>
			For points/lines, I set all sub-samples of the covered pixel to the same color. After rasterizing all 
			primitives into <code>sample_buffer</code>, I computed the final framebuffer color by averaging
			all sub-samples in each pixel:
		<pre>
			<code>
				C(x,y) = (1 / sample_rate) * sum_{s=0..sample_rate-1} C_s(x,y)
			</code>
		</pre>
			This resolving step converts how many sub-samples were inside the triangle into smoother
			pixel intensities.
		</p>

		<h3>Why supersampling is useful</h3>
		<p>
          Supersampling is useful because it reduces aliasing by approximating the true continuous
          area that a triangle covers within each pixel. Instead of a single on&off decision at the pixel center, pixels
          near edges can become partially covered, producing intermediate colors that look a lot smoother.
        </p>
      
      	<h3>Pipeline modifications</h3>
		<p>Compared to the base rasterization pipeline from task 1, I made these changes:
		<ul>
			<li>I asterized into <code>sample_buffer</code>, not directly into the framebuffer.</li>
			<li>Modified triangle rasterization to test and fill multiple sub-samples per pixel.</li>
			<li>Added a final resolve step that averages sub-samples into one framebuffer color per pixel.</li>
			<li>Resized/reinitialized the supersample buffer when the sample rate or viewport size changes.</li>
		</ul>
		</p>

		<h3>How supersampling antialiases triangles</h3>
		<p>
			Triangle edges usually cut through pixels at arbitrary positions. With 1 sample/pixel, edge pixels
			flip abruptly between filled and unfilled. With higher sample rates, only some sub-samples are inside the triangle,
			so the averaged pixel color becomes proportional to coverage. This ultimatley produces a smooth transition along edges instead
			of the staircase pattern from the baseline implementation.
		</p>
		
		<h3>Images</h3>
		<figure>
			<img src="hw1_2_rate1.png" style="width:50%"/>
			<figcaption>Screenshot #4: basic/test4.svg</figcaption>
			<figcaption>sample rate 1</figcaption>
		</figure>
		<figure>
			<img src="hw1_2_rate4.png" style="width:50%"/>
		    <figcaption>Screenshot #5: basic/test4.svg</figcaption>
			<figcaption>sample rate 4</figcaption>
		</figure>
		<figure>
			<img src="hw1_2_rate16.png" style="width:50%"/>
			<figcaption>Screenshot #6: basic/test4.svg</figcaption>
			<figcaption>sample rate 16</figcaption>
		</figure>

		<h3>Extra Credit</h3>
		<p>  
			In addition to standard grid-based supersampling, I implemented a
			jittered sampling pattern. I replaced the fixed <code>0.5</code> offsets with randomized offsets. 
			To keep results stable and to not have flickering across frames, the jitter is
			deterministic so it produces the same jitter pattern every run while still breaking the regular grid structure.
		</p>
		<p>
			The only change for the extra credit is the sampling pattern (grid centers vs jittered offsets). Uniform grid 
			sampling is highly structured, so it can produce coherent aliasing artifacts when
			triangle edges align with the grid (long diagonals, repeated thin triangles, near-parallel edges). In those cases,
			the error can appear as repeating stair-step patterns vs Jittered sampling. As a result Jittered tends to be less 
			structured (more noise-like) and is often less noticeable than repeating jagged edges.
		</p>


		<div class="grid">
			<figure class="ph">
			<div style="margin-top: 8px;">
				<img src="hw1_2_ec_notjig.png" style="width:50%"/>
			</div>
			<figcaption>
				<div><strong>Grid supersampling (sample rate 1)</strong></div>
			</figcaption>
			<figcaption>
				Grid sampling can show faint repeating stair-step artifacts due to the periodic sampling lattice.
			</figcaption>
			</figure>

			<figure class="ph">
			<div style="margin-top: 8px;">
				<img src="hw1_2_ec_jig.png" style="width:50%"/>
			</div>
			<figcaption>
				<div><strong>Jittered supersampling (same sample rate)</strong></div>
			</figcaption>
			<figcaption>
				Jitter reduces coherent patterns; edges typically look smoother with less structured aliasing.
			</figcaption>
			</figure>
		</div>

		<h2>Task 3: Transforms</h2>
		<p>
			I implemented <code>translate</code>, <code>scale</code>, and <code>rotate</code> in homogeneous 3×3 matrix form. 
			These transforms compose naturally via matrix multiplication and apply to points
			using the <code>*</code> operator for <code>Vector2D</code>.
		</p>
		<h3>My robot</h3>
		<p>
			I edited <code>robot.svg</code> to make the robot wave. I used hierarchical <code>&lt;g transform="..."&gt;</code> groups 
			so that rotations affect entire limbs around a pivot. I also changed the colors of the torso, legs, head, and arms.
		</p>

		<figure>
			<img src="hw1_3.png" alt="My robot.svg screenshot"/>
			<figcaption>My robot.svg rendered image</figcaption>
		</figure>

		<h3>Extra Credit</h3>
		<p>
			I added a GUI feature that allows rotating the viewport using the <code>[</code> and <code>]</code> keys.
			Pressing <code>[</code> rotates the view counterclockwise by a small fixed angle, and pressing <code>]</code>
			rotates clockwise. This makes it easy to inspect aliasing/artifacts from different angles without modifying the SVG.
		</p>
		<p>
			The rasterizer uses a matrix stack to transform geometry from SVG space into
			Normalized Device Coordinates (NDC), and then from NDC into screen space.
			To implement rotation, I introduced a <code>view_rotation</code> parameter
			that is updated when <code>[</code>/<code>]</code> are pressed, and I inserted a rotation
			matrix into the transform pipeline.
  		</p>
		<p>
			I implemented viewport rotation by applying a 2D rotation around the center of the view in NDC space.
			Since NDC is in a normalized coordinate frame, it is convenient to rotate about the origin; however, the visible
			region is centered at <code>(0,0)</code> in NDC only if the SVG→NDC mapping is centered appropriately.
			In my implementation, I rotated in NDC around the view center using a translate-rotate-translate pattern.
		</p>

		<h3>Images</h3>
		<div class="grid">
			<figure class="ph">
			<div><strong>With rotation using [</strong></div>
			<div style="margin-top: 8px;">
				<img src="hw1_3_extrac1.png"/>
			</div>
			</figure>

			<figure class="ph">
			<div><strong>>With rotation using ]</strong></div>
			<div style="margin-top: 8px;">
				<img src="hw1_3_extrac2.png"/>
			</div>
			</figure>
		</div>

		<h2>Task 4: Barycentric coordinates</h2>
		<p>
			Barycentric coordinates express a point inside a triangle as a weighted combination of the triangle’s vertices.
			The weights <em>(α, β, γ)</em> sum to 1. If all weights are between 0 and 1, the point lies inside the triangle.
			I used these weights to smoothly interpolate per-vertex colors across the triangle:
			<em>C = α·C₀ + β·C₁ + γ·C₂</em>. To render triangles with smoothly varying vertex colors, I implemented
			<code>RasterizerImp::rasterize_interpolated_color_triangle(...)</code> using
			those barycentric coordinates. 
		</p>

		<h3>How barycentric coordinates help with color interpolation</h3>
		<p>
			Once I compute <code>α, β, γ</code> for a sample point <code>p</code>, I interpolate color by applying the same
			weights to the vertex colors:
		</p>
			<pre><code>C(p) = α C0 + β C1 + γ C2</code></pre>
		<p>
			This produces a smooth gradient across the triangle: each pixel/sub-sample gets a color that is a blend of the three
			vertex colors, weighted by closeness to each vertex.
		</p>

		<figure>
			<img src="hw1_4.png" style="width:50%"/>
			<figcaption>basic/test7.svg</figcaption>
			<figcaption>sample rate 1</figcaption>
		</figure>


		<h2>Task 5: "Pixel sampling" for texture mapping</h2>
		<p>
			Pixel sampling is how the renderer chooses a texture color for a given screen-space sample point.
			After rasterization determines that a sample lies inside a triangle, the triangle’s texture coordinates (<code>u,v</code>)
			are interpolated to that sample location. Pixel sampling then takes the continuous <code>(u,v)</code>
			position on the texture image and converts it into an actual color value from the texture pixel grid.
		</p>
		<p>
			In my texture mapping pipeline, the steps are as follows:
		</p>
		<ol>
			<li>Rasterize triangle and compute barycentric coordinates at each sub-sample.</li>
			<li>Use barycentric interpolation to compute the texture coordinate <code>(u,v)</code> at that sub-sample.</li>
			<li>Call the texture sampler with <code>(u,v)</code> to retrieve a color from the texture.</li>
			<li>Write that color into the supersample buffer; later resolve by averaging (if supersampling is enabled).</li>
		</ol>

		<h3>Nearest vs. bilinear sampling</h3>
		<h4>Nearest sampling</h4>
		<p>
			Nearest sampling chooses the color of the single texture pixel whose center is closest to the queried
			<code>(u,v)</code>. Nearest sampling is fast and simple, but it can produce visible blockiness and shimmering 
			because the chosen texture pixel can change abruptly as <code>(u,v)</code> moves slightly.
		</p>
		<h4>Bilinear sampling</h4>
		<p>
			Bilinear sampling uses the four texure pixels surrounding <code>(u,v)</code> and computes a weighted average based on the
			fractional offset within the texture pixel cell. This smooths transitions across texture pixels and usually 
			reduces blockiness especially when the texture is magnified on screen.
		</p>

		<div class="grid">
			<figure class="ph">
			<div><strong>Nearest sampling, 1 sample per pixel</strong></div>
			<div style="margin-top: 8px;">
				<img src="hw1_5_sample1_nearest.png" style="width:50%"/>
			</div>
			</figure>

			<figure class="ph">
			<div><strong>Nearest sampling, 16 samples per pixel</strong></div>
			<div style="margin-top: 8px;">
				<img src="hw1_5_sample16_nearest.png" style="width:50%"/>
			</div>
			</figure>

			<figure class="ph">
			<div><strong>Bilinear sampling, 1 sample per pixel</strong></div>
			<div style="margin-top: 8px;">
				<img src="hw1_5_sample1_linear.png" style="width:50%"/>
			</div>
			</figure>

			<figure class="ph">
			<div><strong>Bilinear sampling, 16 samples per pixel</strong></div>
			<div style="margin-top: 8px;">
				<img src="hw1_5_sample16_linear.png" style="width:50%"/>
			</div>
			</figure>
		</div>

		<h3>Comments on the relative differences</h3>
		<p>
			Nearest sampling looks blocky when a texture is magnified, because each screen sample snaps to
			a single texel. Even with higher supersampling, supersampling mainly reduces aliasing at
			triangle edges and improves coverage estimation, but it does not fully remove the pixelated look inside the
			textured region when nearest sampling is used. Bilinear sampling produces smoother texture 
			appearance because it blends between neighboring texture pixels,
			reducing abrupt jumps in color.
		</p>

		<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
		<p>
			Level sampling helps decide which mipmap resolution to sample from when looking up a texture color.
			If a triangle is far away or really slanted, that pixel might cover a big region of the texture. 
			If we still sample the texture at full resolution (level 0), this cram lots
			of high-frequency detail into one pixel which translates to shimmering or antialiasing crawling edges.
			Level sampling fixes this by choosing an appropriate texture “zoom level.” Level sampling 
			ultimatley chooses which resolution of the texture to best fit.
		</p>

		<h3>How I implemented it</h3>
		<p>
			In <code>RasterizerImp::rasterize_textured_triangle</code>, for each covered sub-sample I computed barycentric
			coordinates and used them to interpolate the texture coordinate <code>(u,v)</code> at:
		</p>
		<ul>
			<li><code>(x, y)</code> → stored as <code>sp.p_uv</code></li>
			<li><code>(x + 1, y)</code> → stored as <code>sp.p_dx_uv</code></li>
			<li><code>(x, y + 1)</code> → stored as <code>sp.p_dy_uv</code></li>
		</ul>
		<p>
			These three UV values approximate <code>(du/dx, dv/dx)</code> and <code>(du/dy, dv/dy)</code>. Inside
			<code>Texture::get_level</code>, I subtracted to form the difference vectors:
		</p>
			<pre><code>dUVdx = sp.p_dx_uv - sp.p_uv
			dUVdy = sp.p_dy_uv - sp.p_uv</code></pre>
		<p>
			Then I scale them into the texure pixel space by multiplying by the base texture width/height. This gives the
			screen-space texture footprint, and I computed the mip level using the lecture formula:
		</p>
			<pre><code>level = log2( max( ||dUVdx||, ||dUVdy|| ) )</code></pre>
		<p>
			Finally, in <code>Texture::sample</code>, I use <code>sp.lsm</code> to choose how to sample mip levels.
		</p>

		<h3>Level sampling modes</h3>
		<ul>
			<li>
			<strong>L_ZERO</strong>: Always sample mip level 0 - same as Task 5
			</li>
			<li>
			<strong>L_NEAREST</strong>: Compute a mip level and round to the nearest integer level before sampling.
			</li>
			<li>
			<strong>L_LINEAR</strong>: Compute a continuous mip level and blend between the two neighboring levels.
			</li>
		</ul>

		<h3>Tradeoffs: speed, memory, and antialiasing power</h3>
		<p>
			Now we can control three different "modes": samples per pixel (supersampling), pixel sampling, and level
			sampling. Each one tackles a different aliasing problem.
		</p>

		<ul>
			<li>
			<strong>Supersampling (higher sample rate)</strong>:
			best for antialiasing triangle edges and coverage, but costs more time and uses a larger sample buffer
			</li>
			<li>
			<strong>Pixel sampling (P_NEAREST vs P_LINEAR)</strong>:
			controls filtering within one mip level. Nearest is fastest but can look blocky during magnification and
			bilinear is slightly slower but overall more smooth.
			</li>
			<li>
			<strong>Level sampling (L_ZERO / L_NEAREST / L_LINEAR)</strong>:
			controls filtering across mipmap levels and primarily reduces minification aliasing.
			Mipmaps use more memory because they store multiple downsampled levels, but level sampling is usually
			much faster than supersampling for minification.
			</li>
		</ul>

		<h3>Images</h3>

		<div class="grid">
			<figure class="ph">
			<div><strong>L_ZERO + P_NEAREST</strong></div>
			<div style="margin-top: 8px;">
				<img src="hw1_6_l_zero&p_nearest.png" style="width:50%"/>
			</div>
			<figcaption>Most aliasing/shimmer when the texture is minified because it always samples full-res level 0.</figcaption>
			</figure>

			<figure class="ph">
			<div><strong>L_ZERO + P_LINEAR</strong></div>
			<div style="margin-top: 8px;">
				<img src="hw1_6_lzero&p_linear.png" style="width:50%"/>
			</div>
			<figcaption>Smoother magnification than nearest, but still aliases during minification since it stays on level 0.</figcaption>
			</figure>

			<figure class="ph">
			<div><strong>L_NEAREST + P_NEAREST</strong></div>
			<div style="margin-top: 8px;">
				<img src="hw1_6_l_nearest_pnearest.png" style="width:50%"/>
			</div>
			<figcaption>Reduced aliasing by sampling an appropriate mip level, but can show blocky transitions across mip levels.</figcaption>
			</figure>

			<figure class="ph">
			<div><strong>L_NEAREST + P_LINEAR</strong></div>
			<div style="margin-top: 8px;">
				<img src="hw1_6_l_nearest_plinear.png" style="width:50%"/>
			</div>
			<figcaption>The best of these four: correct mip choice + smoother within-level filtering.</figcaption>
			</figure>
		</div>
		
		<h2>(Optional) Task 7: Extra Credit - Draw Something Creative!</h2>
		
		</div>
	</body>
</html>
